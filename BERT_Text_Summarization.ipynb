{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LLM-Powered Blog Summarizer: Exploring Cutting-Edge Techniquesm\n",
        "In today's world of too much online information, it's important to quickly understand long blog posts. That's where Language Model (LLM) technologies come in. They're changing how we read and shorten big amounts of text. This project, called \"LLM-Powered Blog Summarizer: Exploring Cutting-Edge Techniques,\" looks into these advanced models.\n",
        "\n",
        "Start by picking out useful information from long blog posts. Using top LLMs\n",
        "like BART, T5, and Pegasus, summarize blogs accurately and efficiently.\n",
        "\n",
        "By useing different LLMs, each with its own way of working, to make short summaries of long blogs. By using BART, T5, and Pegasus models, find out what works best and compare their results.\n",
        "\n",
        "Also check how similar the summaries are to a reference using cosine similarity. This helps us see if the summarization techniques are working well.\n",
        "\n"
      ],
      "metadata": {
        "id": "sxNsAyqNp5f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1vqaqcI5sA4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338e72c3-02f3-4bee-cfbf-0262a3e6b35c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Blog Content\n",
        "Read the content of a blog.Acess the source and open the file, read its contents, and store them in a variable to work with them later."
      ],
      "metadata": {
        "id": "P6jYW5yWrJLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7xzLSENCq315"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- import re,string ----\n",
        "import re\n",
        "import string\n",
        "\n",
        "file_path = './blog.txt'\n",
        "#--- Read in blog.txt file ----\n",
        "with open(file_path,'r', encoding='utf-8') as file:\n",
        "  blog_content = file.read()\n",
        "\n",
        "#--- Inspect Blog txt ---\n",
        "blog_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "5ub9NIjdrTMF",
        "outputId": "6cca989e-9f9f-448e-9f07-d02745b6429a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Rise of Citizen Science: How Everyday People Are Contributing to Research\\nCitizen science is the involvement of the general public in scientific research. It's a collaborative effort where anyone, regardless of their scientific background, can participate in collecting and analyzing data. This approach has gained significant momentum in recent years, driven by several factors:\\n\\nAdvancement in technology: Online platforms and mobile apps have made it easier than ever for individuals to contribute to research projects. These tools allow for data collection, analysis, and collaboration on a global scale.\\nGrowing public interest in science: There's an increasing public desire to understand and contribute to scientific advancements. Citizen science projects provide accessible entry points for people to engage with science in a meaningful way.\\nNeed for broader data collection: Many scientific fields require large datasets to address complex challenges. Citizen science projects can help gather vast amounts of data that would be difficult or expensive to collect through traditional methods.\\nHere are some examples of how citizen science is making a difference:\\n\\nAstronomy: Galaxy Zoo, a project that enlists volunteers to classify galaxies based on their images, has helped astronomers identify new types of galaxies and understand their formation.\\nEcology: iNaturalist, a platform for sharing observations of plants and animals, has contributed valuable data for biodiversity monitoring and conservation efforts.\\nClimate change: The Zooniverse platform hosts numerous projects where volunteers analyze climate data, such as classifying cloud types in satellite imagery, to help scientists understand weather patterns and climate change impacts.\\nCitizen science offers several benefits:\\n\\nEnhanced scientific discovery: By engaging a wider audience, citizen science can accelerate scientific progress and innovation.\\nPublic engagement with science: It fosters public understanding of science and its role in addressing global challenges.\\nEmpowering individuals: Citizen science projects allow individuals to contribute to meaningful research and feel connected to the scientific community.\\nAs technology continues to evolve and public interest in science grows, citizen science is poised to play an even greater role in shaping the future of scientific discovery. If you're interested in getting involved, there are numerous citizen science projects available online, catering to various interests and skill levels. So, why not explore and see how you can contribute to the advancement of scientific knowledge?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cleaning Blog Text\n",
        "Clean up the text to make it easier to work with. Convert the text to lower case and remove any special characters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "93AMjYx3tUK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert blog to lower case\n",
        "text=blog_content.lower()\n",
        "# cleaned_text\n",
        "def remove_special_characters(text):\n",
        "    # Define the pattern to match special characters\n",
        "    pattern = r'[^a-zA-Z0-9\\s]'\n",
        "\n",
        "    # Use the sub() function to replace matches with an empty string\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "\n",
        "    # Remove extra spaces by replacing consecutive spaces with a single space\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
        "\n",
        "    return cleaned_text.strip()\n",
        "cleaned_text = remove_special_characters(text )\n",
        "\n",
        "#--- Inspect cleaned_text ---\n",
        "cleaned_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "SoS4zqkUtWua",
        "outputId": "e712bca0-7892-4e56-ddbd-3881a4ef61e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the rise of citizen science how everyday people are contributing to research citizen science is the involvement of the general public in scientific research its a collaborative effort where anyone regardless of their scientific background can participate in collecting and analyzing data this approach has gained significant momentum in recent years driven by several factors advancement in technology online platforms and mobile apps have made it easier than ever for individuals to contribute to research projects these tools allow for data collection analysis and collaboration on a global scale growing public interest in science theres an increasing public desire to understand and contribute to scientific advancements citizen science projects provide accessible entry points for people to engage with science in a meaningful way need for broader data collection many scientific fields require large datasets to address complex challenges citizen science projects can help gather vast amounts of data that would be difficult or expensive to collect through traditional methods here are some examples of how citizen science is making a difference astronomy galaxy zoo a project that enlists volunteers to classify galaxies based on their images has helped astronomers identify new types of galaxies and understand their formation ecology inaturalist a platform for sharing observations of plants and animals has contributed valuable data for biodiversity monitoring and conservation efforts climate change the zooniverse platform hosts numerous projects where volunteers analyze climate data such as classifying cloud types in satellite imagery to help scientists understand weather patterns and climate change impacts citizen science offers several benefits enhanced scientific discovery by engaging a wider audience citizen science can accelerate scientific progress and innovation public engagement with science it fosters public understanding of science and its role in addressing global challenges empowering individuals citizen science projects allow individuals to contribute to meaningful research and feel connected to the scientific community as technology continues to evolve and public interest in science grows citizen science is poised to play an even greater role in shaping the future of scientific discovery if youre interested in getting involved there are numerous citizen science projects available online catering to various interests and skill levels so why not explore and see how you can contribute to the advancement of scientific knowledge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarizing Blog Content\n",
        "Ceate a summary of the blogby using BART to help us with this task. First, load the BART tokenizer and model then tokenize the cleaned text and feed it into the model to generate a summary. The summary will capture the main points of the blog in a concise form. Once generated, save the summary to a file for future reference."
      ],
      "metadata": {
        "id": "WQWQdQN_tb0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0haMDZhxtuuS",
        "outputId": "b37a2790-cf01-446d-f861-630cf114702a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- import BartTokenizer, TFBartForConditionalGeneration from transformers ---\n",
        "from transformers import TFBartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = TFBartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer.encode(\n",
        "    cleaned_text,\n",
        "    return_tensors=\"tf\",\n",
        "    max_length=1024,\n",
        "    truncation=True\n",
        ")\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(\n",
        "    inputs,\n",
        "    max_length=300,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n",
        "# Decode and print the generated summary\n",
        "summary_bart = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "#Export the Generated text (\"summary_bart.txt\")\n",
        "# output_filepath = \"summary_bart.txt\"\n",
        "output_filepath=\"./sumarry_bart.txt\"\n",
        "# with open(output_filepath, \"w\", encoding=\"utf-8\") as output_file:\n",
        "with open(output_filepath,\"w\", encoding=\"utf-8\") as output_file:\n",
        "    output_file.write(summary_bart)\n",
        "\n",
        "# output_file.write(summary_bart)\n",
        "summary_bart\n"
      ],
      "metadata": {
        "id": "Z-RMZqv-timA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rfjXqndHfGWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Alternative Blog Summarization with T5 Model\n",
        "Summarizing the blog content using T5. Similar to before, load the T5 tokenizer and model. Then tokenize the cleaned text and feed it into the model to generate a summary. The summary will capture the main points of the blog in a concise form. Once generated, save the summary to a file for future reference.\n",
        "\n"
      ],
      "metadata": {
        "id": "sH4eanDE3Lio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SentencePiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_9tRyac42KK",
        "outputId": "eeb365a3-1091-4257-c2a1-5f23330a4ae8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- import T5Tokenizer, TFT5ForConditionalGeneration from transformers ---\n",
        "\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "# Load the tokenizer and model\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = TFT5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Tokenize the input text\n",
        "\n",
        "inputs = tokenizer.encode(\n",
        "    cleaned_text,\n",
        "    return_tensors=\"tf\",\n",
        "    max_length=1024,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(\n",
        "    inputs,\n",
        "    max_length=150,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Decode and print the generated summary\n",
        "summary_t5 = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "#Export the Generated text (\"summary_t5.txt\")\n",
        "# output_filepath = \"summary_t5.txt\"\n",
        "output_filepath=\"summary_t5.txt\"\n",
        "# with open(output_filepath, \"w\", encoding=\"utf-8\") as output_file:\n",
        "\n",
        "with open(output_filepath,\"w\") as output_file:\n",
        "\n",
        "    output_file.write(summary_t5)\n",
        "\n",
        "#     output_file.write(summary_text)\n",
        "summary_t5"
      ],
      "metadata": {
        "id": "nff6hHbT3Ngh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Employing Pegasus Model for Blog Summarization\n",
        "Another method Pegasus, load the Pegasus tokenizer and model Then tokenize the cleaned text and feed it into the model to generate a summary. The summary will give us a condensed version of the blog's key points. Once generated, we'll save the summary to a file for future reference."
      ],
      "metadata": {
        "id": "tu9lUDtvBwke"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOEezGugDPHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- import PegasusTokenizer, TFPegasusForConditionalGeneration from transformers ---\n",
        "from transformers import TFPegasusForConditionalGeneration, PegasusTokenizer\n",
        "# Load the tokenizer and model\n",
        "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
        "model = TFPegasusForConditionalGeneration.from_pretrained('google/pegasus-large')\n",
        "# Tokenize the input text\n",
        "input=tokenizer.encode(\n",
        "    cleaned_text,\n",
        "    return_tensors=\"tf\",\n",
        "    max_length=1024,\n",
        "    truncation=True,\n",
        ")\n",
        "\n",
        "# Generate the summary\n",
        "\n",
        "summary_ids=model.generate(\n",
        "    inputs,\n",
        "    max_length=150,\n",
        "    num_beams=4,\n",
        "    length_penalty=2.0,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Decode and print the generated summary\n",
        "summary_pegasus = tokenizer.decode(summary_ids[0],skip_special_tokens=True)\n",
        "\n",
        "#Export the Generated text (\"summary_pegasus.txt\")\n",
        "# output_filepath = \"summary_pegasus.txt\"\n",
        "output_filepath=\"summary_pegasus.txt\"\n",
        "\n",
        "# with open(output_filepath, \"w\", encoding=\"utf-8\") as output_file:\n",
        "\n",
        "with open(output_filepath, \"w\") as output_file:\n",
        "  output_file.write(summary_pegasus)\n",
        "\n",
        "#     output_file.write(summary_pegasus)\n",
        "summary_pegasus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ctQGRtBiuj",
        "outputId": "f9ada581-3140-4469-a11b-94af01245875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFPegasusForConditionalGeneration.\n",
            "\n",
            "Some layers of TFPegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['final_logits_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    }
  ]
}